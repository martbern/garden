# Advanced regularisation for neural networks
<!-- #anki/deck/ML -->

Q. Which regularisation methods are specific to neural networks?
A. 1) Dropout and 2) Early stopping

Q. What is the procedure for dropout normalisation?
A. For each training example, you randomly disable some units from the network

Q. Why does dropout normalisation work?
A. Penalises fitting strongly to specific features, as the units making the strong fit may be disabled at random

Q.

## Backlinks
* [[Regularisation]]
	* [[Advanced regularisation for neural networks]]

<!-- {BearID:0DE09345-3C7A-4DC9-9CB6-9C916C2A1F12-886-00000753DE975FE4} -->
